{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMGxfFDU/uitDr9gUWjC5lq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BarelHeby/Deep-Learning---Chest-X-Ray/blob/main/Deep_Learning_Chest_Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "**FIRST SETUP**"
      ],
      "metadata": {
        "id": "G3B7bvb-5iWZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQs7UYex44Fs"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle\n",
        "from google.colab import files\n",
        "\n",
        "# Create a Kaggle API token and save it to a file.\n",
        "!echo '{\"username\":\"barelheby\",\"key\":\"978bdd6cd1cc991c69bbe920fe75a9cc\"}' > kaggle.json\n",
        "\n",
        "# Copy the Kaggle API token file to the correct location.\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/kaggle.json\n",
        "\n",
        "# Change the permissions of the Kaggle API token file.\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download the dataset from Kaggle.\n",
        "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia\n",
        "\n",
        "# Unzip the downloaded dataset.\n",
        "!unzip chest-xray-pneumonia.zip\n",
        "\n",
        "# Print the contents of the current working directory.\n",
        "!ls\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**IMPORTS**"
      ],
      "metadata": {
        "id": "d7wq0ds96-sN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from os.path import join\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "al1niDEz7ICS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        " **Configuration**\n"
      ],
      "metadata": {
        "id": "iEw76ZnW9wkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TF_BATCH_SIZE = 32\n",
        "TF_SEED = 123\n",
        "IMG_HEIGHT = 256\n",
        "IMG_WIDTH = 256\n",
        "DIR_DATASET = \"/content/chest_xray\""
      ],
      "metadata": {
        "id": "fU4yOUMT934-"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Normalize Image Function**"
      ],
      "metadata": {
        "id": "_ktR0gZsHSrt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Training Set Preprocess**"
      ],
      "metadata": {
        "id": "NQOLQigP7Reu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_directory = join(DIR_DATASET,\"train\")\n",
        "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_directory,\n",
        "    validation_split=0.2,\n",
        "    subset = \"training\",\n",
        "    seed = TF_SEED,\n",
        "    image_size = (IMG_HEIGHT,IMG_WIDTH),\n",
        "    batch_size = TF_BATCH_SIZE,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MmsOH817dbC",
        "outputId": "4b26f659-2eeb-45fe-e067-38cb729b0b71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5216 files belonging to 2 classes.\n",
            "Using 4173 files for training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Validation Set Prep**"
      ],
      "metadata": {
        "id": "Ladr4s8i_PzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_directory,\n",
        "    validation_split=0.2,\n",
        "    subset = \"validation\",\n",
        "    seed = TF_SEED,\n",
        "    image_size = (IMG_HEIGHT,IMG_WIDTH),\n",
        "    batch_size = TF_BATCH_SIZE\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wachYFoC_aDu",
        "outputId": "66a05bc4-0cb4-4ce2-a779-67fae0dc5027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5216 files belonging to 2 classes.\n",
            "Using 1043 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8bcjU-_B8s9",
        "outputId": "5ec2860a-e7a4-4c0f-da06-0aed600f8fb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NORMAL', 'PNEUMONIA']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_encoded_class_names = [i for (i,label) in enumerate(train_dataset.class_names)]\n",
        "validation_encoded_class_names = [i for (i,label) in enumerate(validation_dataset.class_names)]\n"
      ],
      "metadata": {
        "id": "9KMHcbO_CO1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.map(lambda x,y:(x/255.0,y))\n",
        "validation_dataset = validation_dataset.map(lambda x,y:(x/255.0,y))"
      ],
      "metadata": {
        "id": "meqKwjioFjO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Part 1 Model**"
      ],
      "metadata": {
        "id": "dnBYEXPnJ40x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from keras.layers import BatchNormalization,Dropout,Dense,Flatten\n",
        "from tensorflow.keras.optimizers import Adamax,Adam\n"
      ],
      "metadata": {
        "id": "pOEXaQfVKHM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_network = VGG16(weights=\"imagenet\",include_top=False,input_shape = (IMG_HEIGHT,IMG_WIDTH,3),pooling=\"avg\")\n",
        "base_network.trainable = False"
      ],
      "metadata": {
        "id": "4vAnDbYkK_uR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_assigment_1  = Sequential(name=\"Assigment_1\")\n",
        "model_assigment_1.add(base_network)\n",
        "model_assigment_1.add(Flatten())\n",
        "model_assigment_1.add(Dense(512,activation=\"relu\"))\n",
        "model_assigment_1.add(Dropout(0.50))\n",
        "model_assigment_1.add(Dense(128,activation=\"relu\"))\n",
        "model_assigment_1.add(Dropout(0.25))\n",
        "model_assigment_1.add(Dense(60,activation=\"relu\"))\n",
        "model_assigment_1.add(Dense(1,activation=\"sigmoid\"))\n",
        "model_assigment_1.compile(optimizer=Adam(),loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_assigment_1.summary()"
      ],
      "metadata": {
        "id": "SOivLluzMHJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "history = model_assigment_1.fit(train_dataset,\n",
        "                        epochs= 10,\n",
        "                        validation_data = validation_dataset,\n",
        "                        callbacks = early_stopping)"
      ],
      "metadata": {
        "id": "QgUx0ox5Nxhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_loss, validation_accuracy = model_assigment_1.evaluate(validation_dataset)\n",
        "print(\"Validation Loss:\", validation_loss)\n",
        "print(\"Validation Accuracy:\", validation_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDlDvvpoUXZ6",
        "outputId": "8eb85fd3-e4e0-46ef-cae4-60a6c465cc17"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33/33 [==============================] - 11s 278ms/step - loss: 0.0786 - accuracy: 0.9741\n",
            "Validation Loss: 0.07857345789670944\n",
            "Validation Accuracy: 0.9741131067276001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil"
      ],
      "metadata": {
        "id": "kR0aJtxFerzp"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DIR_ASS_2 = join(DIR_DATASET,\"assiment_2_dataset\")\n",
        "DIR_ASS_2_BACTERIA  = join(DIR_ASS_2,\"BACTERIA\")\n",
        "DIR_ASS_2_VIRUS = join(DIR_ASS_2,\"VIRUS\")\n",
        "DIR_ASS_2_NORMAL = join(DIR_ASS_2,\"NORMAL\")\n"
      ],
      "metadata": {
        "id": "OErYi3TlgiCf"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  shutil.rmtree(DIR_ASS_2)\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "try:\n",
        "  os.mkdir(DIR_ASS_2)\n",
        "  os.mkdir(DIR_ASS_2_BACTERIA)\n",
        "  os.mkdir(DIR_ASS_2_VIRUS)\n",
        "  os.mkdir(DIR_ASS_2_NORMAL)\n",
        "except Exception as e:\n",
        "  print(e)"
      ],
      "metadata": {
        "id": "FsSMjr0CfRrl"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Copy Images From Source To New Folder**"
      ],
      "metadata": {
        "id": "VKBKOV99h4n6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy sick"
      ],
      "metadata": {
        "id": "C-bWYt2fiDij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: copy all files from DIR_DATASET/test/PNEUMONIA to DIR_DATASET/assigment_2_dataset\n",
        "source_dir = join(DIR_DATASET,\"train\",\"PNEUMONIA\")\n",
        "for filename in os.listdir(source_dir):\n",
        "  if \"bacteria\" in filename.lower():\n",
        "    dest_dir  = DIR_ASS_2_BACTERIA\n",
        "  elif \"virus\" in filename.lower():\n",
        "    dest_dir = DIR_ASS_2_VIRUS\n",
        "  else:\n",
        "    pass\n",
        "  shutil.copy(join(source_dir,filename),dest_dir)\n",
        "\n"
      ],
      "metadata": {
        "id": "2MshG1dJfrkr"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy normal"
      ],
      "metadata": {
        "id": "lacbfrSciFMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source_dir = join(DIR_DATASET,\"train\",\"NORMAL\")\n",
        "for filename in os.listdir(source_dir):\n",
        "  shutil.copy(join(source_dir,filename),DIR_ASS_2_NORMAL)"
      ],
      "metadata": {
        "id": "oMGgJJvRiIKw"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Assigment 2 preprocess**"
      ],
      "metadata": {
        "id": "8u-3Fm62jKyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_ass_2 = tf.keras.utils.image_dataset_from_directory(\n",
        "    DIR_ASS_2,\n",
        "    validation_split=0.2,\n",
        "    subset = \"training\",\n",
        "    seed = TF_SEED,\n",
        "    image_size = (IMG_HEIGHT,IMG_WIDTH),\n",
        "    batch_size = TF_BATCH_SIZE,\n",
        ")\n",
        "validation_dataset_ass_2 = tf.keras.utils.image_dataset_from_directory(\n",
        "    DIR_ASS_2,\n",
        "    validation_split=0.2,\n",
        "    subset = \"validation\",\n",
        "    seed = TF_SEED,\n",
        "    image_size = (IMG_HEIGHT,IMG_WIDTH),\n",
        "    batch_size = TF_BATCH_SIZE\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPxw6ANUjQ_E",
        "outputId": "e56715d3-0f6c-459a-c149-e0c0f40b7970"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5216 files belonging to 3 classes.\n",
            "Using 4173 files for training.\n",
            "Found 5216 files belonging to 3 classes.\n",
            "Using 1043 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_encoded_class_names_ass_2 = [i for (i,label) in enumerate(train_dataset_ass_2.class_names)]\n",
        "validation_encoded_class_names_ass_2 = [i for (i,label) in enumerate(validation_dataset_ass_2.class_names)]"
      ],
      "metadata": {
        "id": "0zC8pupSjyC8"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_ass_2 = train_dataset_ass_2.map(lambda x,y:(x/255.0,y))\n",
        "validation_dataset_ass_2 = validation_dataset_ass_2.map(lambda x,y:(x/255.0,y))"
      ],
      "metadata": {
        "id": "KJw5x_pzkDb_"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_network_ass_2 = VGG16(weights=\"imagenet\",include_top=False,input_shape = (IMG_HEIGHT,IMG_WIDTH,3),pooling=\"avg\")\n",
        "base_network_ass_2.trainable = False"
      ],
      "metadata": {
        "id": "BMcIKj7kkprY"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_assigment_2  = Sequential(name=\"Assigment_2\")\n",
        "model_assigment_2.add(base_network_ass_2)\n",
        "model_assigment_2.add(Flatten())\n",
        "model_assigment_2.add(Dense(512,activation=\"relu\"))\n",
        "model_assigment_2.add(Dropout(0.50))\n",
        "model_assigment_2.add(Dense(128,activation=\"relu\"))\n",
        "model_assigment_2.add(Dropout(0.25))\n",
        "model_assigment_2.add(Dense(60,activation=\"relu\"))\n",
        "model_assigment_2.add(Dense(2,activation=\"softmax\"))\n",
        "model_assigment_2.compile(optimizer=Adam(),loss='categorical_crossentropy', metrics=['accuracy',\"categorical_accuracy\"])\n",
        "model_assigment_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keEfN3xJksw8",
        "outputId": "9c8d4afc-043d-4148-b992-02a69efc1b6a"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Assigment_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 512)               14714688  \n",
            "                                                                 \n",
            " flatten_27 (Flatten)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_109 (Dense)           (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_58 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_110 (Dense)           (None, 128)               65664     \n",
            "                                                                 \n",
            " dropout_59 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_111 (Dense)           (None, 60)                7740      \n",
            "                                                                 \n",
            " dense_112 (Dense)           (None, 2)                 122       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15050870 (57.41 MB)\n",
            "Trainable params: 336182 (1.28 MB)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "history_ass_2 = model_assigment_2.fit(train_dataset_ass_2,\n",
        "                        epochs= 10,\n",
        "                        validation_data = validation_dataset_ass_2,\n",
        "                        callbacks = early_stopping)"
      ],
      "metadata": {
        "id": "DTHCmTbsk3Vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_ass_2.class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "QtC4Pz1Vl_06",
        "outputId": "bad9d6e1-c078-4aab-8d6a-6013e07b8bad"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'_MapDataset' object has no attribute 'class_names'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-163-e85d883fdec5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset_ass_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: '_MapDataset' object has no attribute 'class_names'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(len(train_dataset))\n",
        "for e in train_dataset:\n",
        "  print(e.count)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSlLEXoUntFd",
        "outputId": "8957b961-60bb-427b-ca2a-b358ffc3b5a3"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "131\n",
            "<built-in method count of tuple object at 0x7a20f410c9c0>\n"
          ]
        }
      ]
    }
  ]
}